{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a26b6366","cell_type":"markdown","source":"# Test the Full Pipeline: Detection and Classification","metadata":{}},{"id":"f793901f","cell_type":"markdown","source":"This notebook runs the complete vehicle processing pipeline:\n1. **Detection**: It uses the fine-tuned YOLO model to detect vehicles in the `traffic_test.mp4` video.\n2. **Classification**: For each detected vehicle, it uses the fine-tuned `EfficientNetB4_CBAM` classifier to identify the car's make and model.\n\nThe final output is a video with bounding boxes and class labels drawn on each frame.","metadata":{}},{"id":"938da3b2-cb0a-4722-9df9-9388a645a7fa","cell_type":"markdown","source":"### Clone Model Code Repository","metadata":{}},{"id":"5f8a5d41-6819-4991-aa3b-0475ef69a1f0","cell_type":"code","source":"!git clone -b feat/pretrained-model https://github.com/luthfiarifin/hybrid-envit-car-retrieval.git code\n!mv code/* .\n!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:02:23.081467Z","iopub.execute_input":"2025-06-24T12:02:23.081766Z","iopub.status.idle":"2025-06-24T12:02:37.587081Z","shell.execute_reply.started":"2025-06-24T12:02:23.081733Z","shell.execute_reply":"2025-06-24T12:02:37.586379Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'code'...\nremote: Enumerating objects: 266, done.\u001b[K\nremote: Counting objects: 100% (1/1), done.\u001b[K\nremote: Total 266 (delta 0), reused 0 (delta 0), pack-reused 265 (from 2)\u001b[K\nReceiving objects: 100% (266/266), 500.85 MiB | 47.01 MiB/s, done.\nResolving deltas: 100% (99/99), done.\nUpdating files: 100% (70/70), done.\n1_run_scraper_into_dataset.ipynb\tcode\t\t requirements.txt\n2_finetune_the_detection_model.ipynb\tdata_processing  traffic_test.mp4\n3_train_the_classification_model.ipynb\tlogs\n4_final_traffic_cam_test.ipynb\t\tmodels\n","output_type":"stream"}],"execution_count":2},{"id":"8d01b830","cell_type":"code","source":"import cv2\nimport torch\nfrom ultralytics import YOLO\nfrom PIL import Image\nfrom torchvision import transforms\nfrom IPython.display import Video, display\nimport os\n\n# Import the model definition from your project files\nfrom models.classification.model import EfficientNetB4_CBAM\n\n# --- Configuration ---\nDETECTION_MODEL_PATH = \"models/detection/yolo_finetune/vehicle_detection/weights/best.pt\"\nCLASSIFICATION_MODEL_PATH = \"models/classification/results/car_classifier_model_20250624_014531_best_acc.pth\"\nVIDEO_PATH = \"traffic_test.mp4\"\nOUTPUT_VIDEO_PATH = \"traffic_test_classified.mp4\"\n\n# This should be the same list of classes used to train the classifier\n# You might need to load this from a file or define it as it was in your training script\nCLASS_NAME_PATH = \"models/classification/class_names.txt\"\nwith open(CLASS_NAME_PATH, \"r\") as f:\n    CLASS_NAMES = [line.strip() for line in f.readlines()]\nNUM_CLASSES = len(CLASS_NAMES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:02:40.800274Z","iopub.execute_input":"2025-06-24T12:02:40.800561Z","iopub.status.idle":"2025-06-24T12:02:44.868154Z","shell.execute_reply.started":"2025-06-24T12:02:40.800536Z","shell.execute_reply":"2025-06-24T12:02:44.867374Z"}},"outputs":[],"execution_count":4},{"id":"3bc8c2da","cell_type":"markdown","source":"### Load the Models","metadata":{}},{"id":"e27b94e7","cell_type":"code","source":"# Load YOLO Detection Model\nprint(f\"Loading detection model from: {DETECTION_MODEL_PATH}\")\ndetection_model = YOLO(DETECTION_MODEL_PATH)\n\n# Load EfficientNetB4_CBAM Classification Model\nprint(f\"Loading classification model from: {CLASSIFICATION_MODEL_PATH}\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nclassification_model = EfficientNetB4_CBAM(num_classes=NUM_CLASSES)\nif torch.cuda.is_available():\n    classification_model.load_state_dict(torch.load(CLASSIFICATION_MODEL_PATH))\nelse:\n    classification_model.load_state_dict(torch.load(CLASSIFICATION_MODEL_PATH, map_location=torch.device('cpu')))\nclassification_model.eval() # Set model to evaluation mode\nclassification_model.to(device)\n\nprint(\"Models loaded successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:02:44.869154Z","iopub.execute_input":"2025-06-24T12:02:44.869539Z","iopub.status.idle":"2025-06-24T12:02:46.058911Z","shell.execute_reply.started":"2025-06-24T12:02:44.869520Z","shell.execute_reply":"2025-06-24T12:02:46.058246Z"}},"outputs":[{"name":"stdout","text":"Loading detection model from: models/detection/yolo_finetune/vehicle_detection/weights/best.pt\nLoading classification model from: models/classification/results/car_classifier_model_20250624_014531_best_acc.pth\nModels loaded successfully.\n","output_type":"stream"}],"execution_count":5},{"id":"dea39dd3","cell_type":"markdown","source":"### Define Image Transformations","metadata":{}},{"id":"4ab51fc2","cell_type":"code","source":"# Define the same transformations used during the classification model training\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:02:46.059764Z","iopub.execute_input":"2025-06-24T12:02:46.059977Z","iopub.status.idle":"2025-06-24T12:02:46.064122Z","shell.execute_reply.started":"2025-06-24T12:02:46.059960Z","shell.execute_reply":"2025-06-24T12:02:46.063372Z"}},"outputs":[],"execution_count":6},{"id":"d58ecfbc","cell_type":"markdown","source":"### Process the Video","metadata":{}},{"id":"552c7bdc","cell_type":"code","source":"from tqdm import tqdm\nimport torch.nn.functional as F  # For softmax\n\ncap = cv2.VideoCapture(VIDEO_PATH)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (width, height))\n\ntotal_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\nprint(f\"Processing video: {VIDEO_PATH}...\")\n\nwith tqdm(total=total_frames, desc=\"Processing frames\") as pbar:\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # 1. Run Detection\n        detection_results = detection_model(frame, verbose=False)\n\n        # 2. Process each detection\n        for result in detection_results:\n            for box in result.boxes:\n                # Get bounding box coordinates\n                x1, y1, x2, y2 = map(int, box.xyxy[0])\n\n                # Crop the detected vehicle\n                vehicle_crop = frame[y1:y2, x1:x2]\n\n                # 3. Classify the vehicle\n                pil_img = Image.fromarray(cv2.cvtColor(vehicle_crop, cv2.COLOR_BGR2RGB))\n                input_tensor = transform(pil_img).unsqueeze(0).to(device)\n                \n                with torch.no_grad():\n                    outputs = classification_model(input_tensor)\n                    probabilities = F.softmax(outputs[0], dim=0)\n                    top1_prob, predicted_idx = torch.topk(probabilities, 1)\n                    class_name = CLASS_NAMES[predicted_idx.item()]\n                    confidence_score = top1_prob.item()\n\n                # 4. Draw bounding box and class label on the frame\n                label = f'Car: {class_name} ({confidence_score:.2f})'\n                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n        \n        # Write the annotated frame to the output video\n        out.write(frame)\n        pbar.update(1)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\nprint(f\"Finished processing. Classified video saved to: {OUTPUT_VIDEO_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:02:46.064975Z","iopub.execute_input":"2025-06-24T12:02:46.065167Z","iopub.status.idle":"2025-06-24T12:20:50.650644Z","shell.execute_reply.started":"2025-06-24T12:02:46.065152Z","shell.execute_reply":"2025-06-24T12:20:50.649757Z"}},"outputs":[{"name":"stdout","text":"Processing video: traffic_test.mp4...\n","output_type":"stream"},{"name":"stderr","text":"Processing frames: 100%|██████████| 5920/5920 [18:04<00:00,  5.46it/s]","output_type":"stream"},{"name":"stdout","text":"Finished processing. Classified video saved to: traffic_test_classified.mp4\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7}]}